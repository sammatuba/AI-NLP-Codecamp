{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Text Preprocessing",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sammatuba/AI-NLP-Codecamp/blob/master/Text_Preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "367Xgr0MO_Ed",
        "colab_type": "text"
      },
      "source": [
        "# **Data Pre-processing** \n",
        "\n",
        "Refers to the transformations applied to our \n",
        "data before feeding it to machine learning algorithms.\n",
        "\n",
        "Most of the industry now are dealing with big data. To improve efficiency, we need to\n",
        "reduce dimensionality by removing some data.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qiZt-M-PhB-t",
        "colab_type": "code",
        "outputId": "8d26cc0c-cfd5-439b-c0f3-ca324e8ddc3b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        }
      },
      "source": [
        "#library\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "#test"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fkqq2YjecOVb",
        "colab_type": "code",
        "outputId": "05eeba31-8ea0-4c5b-918d-bf16a5058ec3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "review =  \"I had a GREAT experience at the golden harbor! I love an order of fried chicken which is enough for 5 persons and it taste so great.I love that place!\"\n",
        "\n",
        "review"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'I had a GREAT experience at the golden harbor! I love an order of fried chicken which is enough for 5 persons and it taste so great.I love that place!'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1mDxSuRdnnPc",
        "colab_type": "text"
      },
      "source": [
        "**Remove number(s)**\n",
        "Numbers can be remove because it does not tell wether the data is positive or negative."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lyj0ZDoynn8p",
        "colab_type": "code",
        "outputId": "5891d8be-de5d-47ed-fcbf-ad634178a0fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "result = ''.join([i for i in review if not i.isdigit()])\n",
        "result"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'I had a GREAT experience at the golden harbor! I love an order of fried chicken which is enough for  persons and it taste so great.I love that place!'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PuqG3ksjnpUt",
        "colab_type": "text"
      },
      "source": [
        "**Set all characters to lowercase**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cuBHbLbmnp8Q",
        "colab_type": "code",
        "outputId": "bbccb8bc-cf91-4b27-edf4-b698359b42ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "result = result.lower()\n",
        "\n",
        "result"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'i had a great experience at the golden harbor! i love an order of fried chicken which is enough for  persons and it taste so great.i love that place!'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pAxk6JIabpZ9",
        "colab_type": "text"
      },
      "source": [
        "**Tokenize Word** is a step which splits longer string into words using spaces and punctuation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PQtxqI_xbt4W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        },
        "outputId": "423ab802-7d2e-4c8e-e7dd-ae03752559b0"
      },
      "source": [
        "from nltk.tokenize import word_tokenize \n",
        "\n",
        "\n",
        "result = word_tokenize(result) \n",
        "\n",
        "result"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['i',\n",
              " 'had',\n",
              " 'a',\n",
              " 'great',\n",
              " 'experience',\n",
              " 'at',\n",
              " 'the',\n",
              " 'golden',\n",
              " 'harbor',\n",
              " '!',\n",
              " 'i',\n",
              " 'love',\n",
              " 'an',\n",
              " 'order',\n",
              " 'of',\n",
              " 'fried',\n",
              " 'chicken',\n",
              " 'which',\n",
              " 'is',\n",
              " 'enough',\n",
              " 'for',\n",
              " 'persons',\n",
              " 'and',\n",
              " 'it',\n",
              " 'taste',\n",
              " 'so',\n",
              " 'great.i',\n",
              " 'love',\n",
              " 'that',\n",
              " 'place',\n",
              " '!']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zGJtv-eknqsX",
        "colab_type": "text"
      },
      "source": [
        "**Remove stop words**  that are not relevant and does not help the algorithm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vzJ-espHnrT6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277
        },
        "outputId": "fe8adfeb-1049-4ab6-8645-c3989fde65ea"
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "  \n",
        "stopw = stopwords.words('english')\n",
        "#stopw\n",
        "     \n",
        "result = [w for w in result if w not in stopw]\n",
        "\n",
        "result"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['great',\n",
              " 'experience',\n",
              " 'golden',\n",
              " 'harbor',\n",
              " '!',\n",
              " 'love',\n",
              " 'order',\n",
              " 'fried',\n",
              " 'chicken',\n",
              " 'enough',\n",
              " 'persons',\n",
              " 'taste',\n",
              " 'great.i',\n",
              " 'love',\n",
              " 'place',\n",
              " '!']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QS9CJiPbnsF_",
        "colab_type": "text"
      },
      "source": [
        "**Stemming** is the process of reducing inflection in words to their root forms even if the stem itself is not a valid word in the Language."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CVrqhy3insx0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        },
        "outputId": "adde53e6-ee55-422f-80ee-e2efb98ab104"
      },
      "source": [
        "from nltk.stem import PorterStemmer \n",
        "stemmer = PorterStemmer()\n",
        "\n",
        "w = [\"served\", \"caring\",\"supervisory\" ,\"better\",\"believes\",\"cookery\",\"supervisory\"]\n",
        "\n",
        "for word in w:\n",
        "  print(stemmer.stem(word)) #served, caring,supervisory ,better,believes,cookery,supervisory"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "serv\n",
            "care\n",
            "supervisori\n",
            "better\n",
            "believ\n",
            "cookeri\n",
            "supervisori\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IRhEuoT4nuWc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "06ab3357-d8bd-478d-8787-e929b52f6234"
      },
      "source": [
        "from nltk.stem import LancasterStemmer \n",
        "stemmer = LancasterStemmer() \n",
        "\n",
        "stemmer.stem(\"believes\") #caring,supervisory ,better,believes,cookery,supervisory"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'believ'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5kNuOVJKnv14",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "9b2e7d2e-fd03-45bb-eca5-87ae4e243503"
      },
      "source": [
        "from nltk.stem import SnowballStemmer\n",
        "\n",
        "#'danish', 'dutch', 'english', 'finnish', 'french', \n",
        "#'german', 'hungarian', 'italian', 'norwegian', \n",
        "#'porter', 'portuguese', 'romanian', 'russian', \n",
        "#'spanish', 'swedish' \n",
        "  \n",
        "sb_stemmer = SnowballStemmer('english') \n",
        "sb_stemmer.stem('believes') #caring,supervisory ,better,believes,cookery,supervisory"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'believ'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vqMHABDf3VNQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277
        },
        "outputId": "f6328997-e2a4-4f21-bdec-d2b159f2c94e"
      },
      "source": [
        "from nltk.stem import PorterStemmer \n",
        "stemmer = PorterStemmer()\n",
        "\n",
        "result_stemm = [stemmer.stem(w) for w in result]\n",
        "\n",
        "result_stemm"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['great',\n",
              " 'experi',\n",
              " 'golden',\n",
              " 'harbor',\n",
              " '!',\n",
              " 'love',\n",
              " 'order',\n",
              " 'fri',\n",
              " 'chicken',\n",
              " 'enough',\n",
              " 'person',\n",
              " 'tast',\n",
              " 'great.i',\n",
              " 'love',\n",
              " 'place',\n",
              " '!']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tqP5DkWa6XAd",
        "colab_type": "text"
      },
      "source": [
        "**Lemmatization** is similar to stemming but it brings context to the words."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5jhjeIIr6XyQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "270b6ba3-b60b-4133-ecae-0a0a094c33fe"
      },
      "source": [
        "from nltk.stem import WordNetLemmatizer \n",
        "lemmatizer = WordNetLemmatizer() \n",
        "\n",
        "result_lemm = [lemmatizer.lemmatize(w) for w in result] #Caring ,better pos =\"a\",believes,cooking,cookbook,cookery,waits,waited,waiting,\"waiting\", pos = 'v'\n",
        "\n",
        "print(list(zip(result,result_lemm)))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('great', 'great'), ('experience', 'experience'), ('golden', 'golden'), ('harbor', 'harbor'), ('!', '!'), ('love', 'love'), ('order', 'order'), ('fried', 'fried'), ('chicken', 'chicken'), ('enough', 'enough'), ('persons', 'person'), ('taste', 'taste'), ('great.i', 'great.i'), ('love', 'love'), ('place', 'place'), ('!', '!')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o9HtYrBQ81bt",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DVbs8zTm3Z49",
        "colab_type": "text"
      },
      "source": [
        "**Combine text**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PZvE1VB_3aoU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "0b34a64f-3620-4eaa-93d7-0439b2ec1eb7"
      },
      "source": [
        "result = ' '.join(result_lemm)\n",
        "\n",
        "result"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'great experience golden harbor ! love order fried chicken enough person taste great.i love place !'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XwMt6ZF3i2GG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#review\n",
        "\n",
        "result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BbZPpiVH4_z6",
        "colab_type": "text"
      },
      "source": [
        "**Create a Function pre-process**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cxnww1eB5Ary",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocessing(text):\n",
        "  \n",
        "  #remove numbers\n",
        "  xresult = ''.join([i for i in text if not i.isdigit()])\n",
        "  \n",
        "  #set to lower case\n",
        "  xresult = xresult.lower()\n",
        "  \n",
        "  xresult = xresult.split()\n",
        "  \n",
        "  #remove stop words\n",
        "  xstopw = stopwords.words('english')\n",
        "  xresult = [w for w in xresult if w not in xstopw]\n",
        "  \n",
        "  #lemmatization\n",
        "  xlemma = WordNetLemmatizer()\n",
        "  xresult = [xlemma.lemmatize(w) for w in xresult]\n",
        "  \n",
        "  preprocessed_text = ' '.join(xresult)\n",
        "    \n",
        "  return preprocessed_text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sBAIiuzu6OPI",
        "colab_type": "text"
      },
      "source": [
        "**data frame**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "93cYdO0d6VD4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pandas import DataFrame\n",
        "\n",
        "#create sample data frame\n",
        "data = {'x':['Wow... Loved this place!',\n",
        "             'Crust is not good.',\n",
        "             'Not tasty and the texture was just nasty.',\n",
        "             'A great touch.'],\n",
        "        'y':['1','0','0','1']}   \n",
        "\n",
        "df = DataFrame(data, columns = ['x','y'])\n",
        "\n",
        "#check pre process data\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KFqQzSn909tP",
        "colab_type": "text"
      },
      "source": [
        "**Apply to the dataframe**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bOZzWBaX0dzN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#pre-process x column\n",
        "df['x'] = df['x'].apply(preprocessing)\n",
        "\n",
        "#check pre process data\n",
        "df.head()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iHHSlUBfwiR1",
        "colab_type": "text"
      },
      "source": [
        "# **Thank you**"
      ]
    }
  ]
}