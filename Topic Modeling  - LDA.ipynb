{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sammatuba/AI-NLP-Codecamp/blob/master/Topic%20Modeling%20%20-%20LDA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4hLznZORMCbA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "from sklearn.datasets import fetch_20newsgroups"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8NirYG7wMVkG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "78ceb2bd-3129-479b-b0f4-d592a8b1ef15"
      },
      "source": [
        "dataset = fetch_20newsgroups(shuffle=True,random_state=1,remove=('headers','footers','quotes'))\n",
        "documents = dataset.data\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading 20news dataset. This may take a few minutes.\n",
            "Downloading dataset from https://ndownloader.figshare.com/files/5975967 (14 MB)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "epShd1ZKMlwc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ba1a6b20-006b-432d-bb99-eaa880422934"
      },
      "source": [
        "print(type(documents))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'list'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q2_UYULjMt8i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "no_features = 1000\n",
        "no_topics = 20\n",
        "no_top_words = 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-LIX-7LNTKr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "673fe7c3-14b1-49af-dca8-a59ae514f48c"
      },
      "source": [
        "print(documents[0])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Well i'm not sure about the story nad it did seem biased. What\n",
            "I disagree with is your statement that the U.S. Media is out to\n",
            "ruin Israels reputation. That is rediculous. The U.S. media is\n",
            "the most pro-israeli media in the world. Having lived in Europe\n",
            "I realize that incidences such as the one described in the\n",
            "letter have occured. The U.S. media as a whole seem to try to\n",
            "ignore them. The U.S. is subsidizing Israels existance and the\n",
            "Europeans are not (at least not to the same degree). So I think\n",
            "that might be a reason they report more clearly on the\n",
            "atrocities.\n",
            "\tWhat is a shame is that in Austria, daily reports of\n",
            "the inhuman acts commited by Israeli soldiers and the blessing\n",
            "received from the Government makes some of the Holocaust guilt\n",
            "go away. After all, look how the Jews are treating other races\n",
            "when they got power. It is unfortunate.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dRL6mdyWNcmx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "abcfad00-7ca5-489e-818a-c3f7a99ea4e8"
      },
      "source": [
        "tf_vectorizer = CountVectorizer(max_df=0.90, min_df=2, max_features=no_features,stop_words = 'english')\n",
        "tf = tf_vectorizer.fit_transform(documents)\n",
        "tf_feature_names = tf_vectorizer.get_feature_names()\n",
        "\n",
        "print(\"Number of items in the list: {}\".format(len(tf_feature_names)))\n",
        "print(tf_feature_names)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of items in the list: 1000\n",
            "['00', '000', '01', '02', '03', '04', '0d', '0t', '10', '100', '11', '12', '128', '13', '14', '145', '15', '16', '17', '18', '19', '1990', '1991', '1992', '1993', '1d9', '1st', '1t', '20', '200', '21', '22', '23', '24', '25', '250', '26', '27', '28', '29', '2di', '2tm', '30', '300', '31', '32', '33', '34', '34u', '35', '36', '37', '38', '39', '3d', '3t', '40', '42', '43', '44', '45', '50', '500', '55', '60', '64', '6ei', '70', '75', '75u', '7ey', '7u', '80', '800', '86', '90', '91', '92', '93', '9v', 'a86', 'able', 'ac', 'accept', 'access', 'according', 'act', 'action', 'actually', 'add', 'addition', 'address', 'administration', 'advance', 'age', 'ago', 'agree', 'ah', 'air', 'al', 'algorithm', 'allow', 'allowed', 'alt', 'america', 'american', 'analysis', 'anonymous', 'answer', 'answers', 'anti', 'anybody', 'apparently', 'appears', 'apple', 'application', 'applications', 'appreciate', 'appreciated', 'approach', 'appropriate', 'apr', 'april', 'archive', 'area', 'aren', 'argument', 'armenia', 'armenian', 'armenians', 'arms', 'army', 'article', 'articles', 'ask', 'asked', 'asking', 'assume', 'atheism', 'attack', 'au', 'author', 'authority', 'available', 'average', 'avoid', 'away', 'ax', 'b8f', 'bad', 'base', 'based', 'basic', 'basically', 'basis', 'belief', 'believe', 'best', 'better', 'bh', 'bhj', 'bible', 'big', 'bike', 'bit', 'bits', 'black', 'block', 'blood', 'board', 'body', 'book', 'books', 'bought', 'box', 'break', 'bring', 'brought', 'btw', 'build', 'building', 'built', 'bus', 'business', 'buy', 'bxn', 'ca', 'cable', 'california', 'called', 'calls', 'came', 'canada', 'car', 'card', 'cards', 'care', 'carry', 'cars', 'case', 'cases', 'cause', 'cd', 'center', 'certain', 'certainly', 'chance', 'change', 'changed', 'changes', 'check', 'chicago', 'child', 'children', 'chip', 'chips', 'choice', 'christ', 'christian', 'christianity', 'christians', 'church', 'chz', 'citizens', 'city', 'claim', 'claims', 'class', 'clear', 'clearly', 'clinton', 'clipper', 'close', 'code', 'color', 'com', 'come', 'comes', 'coming', 'command', 'comments', 'commercial', 'common', 'communications', 'community', 'comp', 'company', 'complete', 'completely', 'computer', 'condition', 'conference', 'congress', 'consider', 'considered', 'contact', 'contains', 'context', 'continue', 'control', 'controller', 'copy', 'correct', 'cost', 'couldn', 'country', 'couple', 'course', 'court', 'cover', 'create', 'created', 'crime', 'cross', 'cs', 'current', 'currently', 'cut', 'cx', 'd9', 'data', 'date', 'dave', 'david', 'day', 'days', 'db', 'dc', 'dead', 'deal', 'death', 'decided', 'defense', 'define', 'deleted', 'department', 'des', 'design', 'designed', 'details', 'development', 'device', 'devices', 'did', 'didn', 'die', 'difference', 'different', 'difficult', 'digital', 'directly', 'directory', 'discussion', 'disk', 'display', 'distribution', 'division', 'dod', 'does', 'doesn', 'doing', 'don', 'dos', 'doubt', 'dr', 'drive', 'driver', 'drivers', 'drives', 'drug', 'early', 'earth', 'easily', 'east', 'easy', 'ed', 'edu', 'effect', 'electronic', 'email', 'encryption', 'end', 'enforcement', 'engine', 'entire', 'entry', 'environment', 'error', 'escrow', 'especially', 'event', 'events', 'evidence', 'exactly', 'example', 'excellent', 'exist', 'existence', 'exists', 'expect', 'experience', 'explain', 'export', 'extra', 'face', 'fact', 'faith', 'false', 'family', 'faq', 'far', 'fast', 'faster', 'father', 'fax', 'fbi', 'federal', 'feel', 'field', 'figure', 'file', 'files', 'final', 'finally', 'fine', 'firearms', 'floppy', 'folks', 'follow', 'following', 'food', 'force', 'form', 'format', 'free', 'freedom', 'friend', 'ftp', 'function', 'functions', 'future', 'g9v', 'game', 'games', 'gas', 'gave', 'general', 'generally', 'gets', 'getting', 'gif', 'given', 'gives', 'giving', 'giz', 'gk', 'gm', 'goal', 'god', 'goes', 'going', 'good', 'got', 'gov', 'government', 'graphics', 'great', 'greek', 'ground', 'group', 'groups', 'guess', 'gun', 'guns', 'guy', 'half', 'hand', 'happen', 'happened', 'happens', 'happy', 'hard', 'hardware', 'haven', 'having', 'head', 'health', 'hear', 'heard', 'held', 'hell', 'help', 'hi', 'high', 'higher', 'history', 'hit', 'hockey', 'hold', 'home', 'hope', 'hot', 'hours', 'house', 'hp', 'human', 'ibm', 'ide', 'idea', 'ideas', 'ii', 'image', 'images', 'imagine', 'important', 'include', 'included', 'includes', 'including', 'individual', 'info', 'information', 'input', 'inside', 'installed', 'instead', 'insurance', 'int', 'interested', 'interesting', 'interface', 'internal', 'international', 'internet', 'involved', 'isn', 'israel', 'israeli', 'issue', 'issues', 'jesus', 'jewish', 'jews', 'jim', 'job', 'jobs', 'john', 'jpeg', 'just', 'key', 'keyboard', 'keys', 'kill', 'killed', 'kind', 'knew', 'know', 'knowledge', 'known', 'knows', 'la', 'land', 'language', 'large', 'late', 'later', 'launch', 'law', 'laws', 'league', 'learn', 'leave', 'left', 'legal', 'let', 'letter', 'level', 'library', 'life', 'light', 'like', 'likely', 'limited', 'line', 'lines', 'list', 'little', 'live', 'living', 'lk', 'll', 'local', 'long', 'longer', 'look', 'looked', 'looking', 'looks', 'lord', 'lost', 'lot', 'lots', 'love', 'low', 'lower', 'ma', 'mac', 'machine', 'machines', 'mail', 'main', 'major', 'make', 'makes', 'making', 'man', 'manager', 'manual', 'mark', 'market', 'mass', 'material', 'matter', 'max', 'maybe', 'mb', 'mean', 'meaning', 'means', 'media', 'medical', 'members', 'memory', 'men', 'mention', 'mentioned', 'message', 'mike', 'military', 'million', 'mind', 'mit', 'mode', 'model', 'modem', 'money', 'monitor', 'month', 'months', 'moral', 'motif', 'mouse', 'mr', 'ms', 'multiple', 'nasa', 'national', 'nature', 'near', 'necessary', 'need', 'needed', 'needs', 'net', 'network', 'new', 'news', 'newsgroup', 'nhl', 'nice', 'night', 'non', 'normal', 'north', 'note', 'nsa', 'number', 'numbers', 'object', 'obvious', 'obviously', 'offer', 'office', 'official', 'oh', 'ok', 'old', 'ones', 'open', 'opinion', 'opinions', 'orbit', 'order', 'org', 'organization', 'original', 'os', 'output', 'outside', 'package', 'page', 'paper', 'particular', 'parts', 'party', 'past', 'paul', 'pay', 'pc', 'peace', 'people', 'perfect', 'performance', 'period', 'person', 'personal', 'phone', 'physical', 'pick', 'picture', 'pin', 'pittsburgh', 'pl', 'place', 'places', 'plan', 'play', 'player', 'players', 'plus', 'point', 'points', 'police', 'policy', 'political', 'population', 'port', 'position', 'possible', 'possibly', 'post', 'posted', 'posting', 'power', 'pp', 'present', 'president', 'press', 'pretty', 'previous', 'price', 'printer', 'privacy', 'private', 'pro', 'probably', 'problem', 'problems', 'process', 'product', 'products', 'program', 'programs', 'project', 'protect', 'provide', 'provided', 'provides', 'pts', 'pub', 'public', 'published', 'purpose', 'quality', 'question', 'questions', 'quite', 'radio', 'ram', 'range', 'rate', 'read', 'reading', 'real', 'really', 'reason', 'reasonable', 'reasons', 'received', 'recent', 'recently', 'record', 'red', 'reference', 'related', 'release', 'religion', 'religious', 'remember', 'reply', 'report', 'reported', 'reports', 'request', 'require', 'required', 'requires', 'research', 'response', 'rest', 'result', 'results', 'return', 'right', 'rights', 'road', 'rom', 'room', 'rules', 'run', 'running', 'runs', 'russian', 'safety', 'said', 'sale', 'san', 'satellite', 'save', 'saw', 'say', 'saying', 'says', 'school', 'sci', 'science', 'scientific', 'screen', 'scsi', 'season', 'second', 'secret', 'section', 'secure', 'security', 'seen', 'self', 'sell', 'send', 'sense', 'sent', 'serial', 'series', 'server', 'service', 'set', 'shall', 'shipping', 'short', 'shot', 'shuttle', 'similar', 'simple', 'simply', 'sin', 'single', 'site', 'sites', 'situation', 'size', 'sl', 'small', 'society', 'software', 'solution', 'son', 'soon', 'sorry', 'sort', 'sound', 'sounds', 'source', 'sources', 'south', 'soviet', 'space', 'special', 'specific', 'speed', 'st', 'standard', 'start', 'started', 'state', 'statement', 'states', 'station', 'stephanopoulos', 'steve', 'stop', 'story', 'street', 'strong', 'study', 'stuff', 'subject', 'suggest', 'sun', 'supply', 'support', 'supports', 'supposed', 'sure', 'switch', 'systems', 'taken', 'takes', 'taking', 'talk', 'talking', 'tape', 'tar', 'tax', 'team', 'teams', 'technical', 'technology', 'tell', 'term', 'terms', 'test', 'text', 'thank', 'thanks', 'theory', 'thing', 'things', 'think', 'thinking', 'thought', 'time', 'times', 'title', 'today', 'told', 'took', 'tools', 'total', 'trade', 'transfer', 'tried', 'trouble', 'true', 'truth', 'try', 'trying', 'turkey', 'turkish', 'turks', 'turn', 'tv', 'type', 'uk', 'understand', 'unfortunately', 'unit', 'united', 'university', 'unix', 'unless', 'usa', 'use', 'used', 'useful', 'usenet', 'user', 'users', 'uses', 'using', 'usually', 'value', 'values', 'van', 'various', 've', 'version', 'vga', 'video', 'view', 'voice', 'volume', 'vs', 'w7', 'wait', 'want', 'wanted', 'wants', 'war', 'washington', 'wasn', 'water', 'way', 'ways', 'weapons', 'week', 'weeks', 'went', 'white', 'wide', 'widget', 'willing', 'win', 'window', 'windows', 'wire', 'wish', 'wm', 'women', 'won', 'word', 'words', 'work', 'worked', 'working', 'works', 'world', 'worth', 'wouldn', 'write', 'writing', 'written', 'wrong', 'wrote', 'x11', 'xt', 'year', 'years', 'yes', 'york', 'young']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZuWW1KtO2x5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# fit into LDA model\n",
        "\n",
        "lda_model = LatentDirichletAllocation(n_components=no_topics,max_iter=15,random_state=0)\n",
        "lda = lda_model.fit(tf)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BGX17gcUPtjD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 689
        },
        "outputId": "329896ba-3476-499e-883b-7ba7cf1831cc"
      },
      "source": [
        "for topic_idx, topic in enumerate(lda.components_):\n",
        "  print(\"Topic {}:\".format(topic_idx))\n",
        "  print(\" \".join([tf_feature_names[i] for i in topic.argsort()[:-no_top_words-1:-1]]t))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Topic 0:\n",
            "space 00 nasa 000 launch 1993 earth april satellite data\n",
            "Topic 1:\n",
            "use like car time good just power used speed better\n",
            "Topic 2:\n",
            "file window program output use entry code application section set\n",
            "Topic 3:\n",
            "encryption use privacy public security government information technology access internet\n",
            "Topic 4:\n",
            "drive scsi disk hard drives card controller bit bus monitor\n",
            "Topic 5:\n",
            "just know don like didn said time did got people\n",
            "Topic 6:\n",
            "game team year games season play hockey players league win\n",
            "Topic 7:\n",
            "years new health research medical center study use year number\n",
            "Topic 8:\n",
            "don people think just like know does say make way\n",
            "Topic 9:\n",
            "edu com cx cs w7 02 ah 17 chz lk\n",
            "Topic 10:\n",
            "edu available ftp image server pub version graphics software file\n",
            "Topic 11:\n",
            "mr president israel stephanopoulos going think know israeli jobs don\n",
            "Topic 12:\n",
            "god jesus bible christian church believe faith does christians christ\n",
            "Topic 13:\n",
            "ax max g9v b8f a86 pl 145 1d9 0t 1t\n",
            "Topic 14:\n",
            "key chip bit keys clipper number chips des bits algorithm\n",
            "Topic 15:\n",
            "windows dos software thanks card does know pc use using\n",
            "Topic 16:\n",
            "10 25 15 12 11 16 db 14 20 13\n",
            "Topic 17:\n",
            "mail thanks new send interested email know like list post\n",
            "Topic 18:\n",
            "armenian armenians people turkish jews war said turkey jewish women\n",
            "Topic 19:\n",
            "gun government people law state right rights guns control crime\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sdmE0k2MRY5I",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "d1f75473-3c20-4d68-cd95-92ceea9f1389"
      },
      "source": [
        "tfTest = tf_vectorizer.transform(['random string blah blah'])\n",
        "predict = lda_model.transform(tfTest)\n",
        "print(predict.shape)\n",
        "\n",
        "newDocTopicDist = dict()\n",
        "\n",
        "for idx, val in enumerate(predict[0]):\n",
        "  newDocTopicDist[idx] = predict[0][idx]\n",
        " \n",
        "results = sorted(newDocTopicDist.items(), key=lambda x: x[1], reverse=True)\n",
        "print(results)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 20)\n",
            "[(0, 0.04999999999999999), (1, 0.04999999999999999), (2, 0.04999999999999999), (3, 0.04999999999999999), (4, 0.04999999999999999), (5, 0.04999999999999999), (6, 0.04999999999999999), (7, 0.04999999999999999), (8, 0.04999999999999999), (9, 0.04999999999999999), (10, 0.04999999999999999), (11, 0.04999999999999999), (12, 0.04999999999999999), (13, 0.04999999999999999), (14, 0.04999999999999999), (15, 0.04999999999999999), (16, 0.04999999999999999), (17, 0.04999999999999999), (18, 0.04999999999999999), (19, 0.04999999999999999)]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}